{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2effd665",
   "metadata": {},
   "source": [
    "## Part 1: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da893a29",
   "metadata": {},
   "source": [
    "### 1.1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cd04cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "# Sklearn modules for data splitting, preprocessing, model building and evaluation\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# Models to be used for classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8903e625",
   "metadata": {},
   "source": [
    "### 1.2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea3bc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../data/raw/train.csv\") # stien til datafilen når det er i IdaData.ipynb\n",
    "df = pd.read_csv(\"../../data/raw/train.csv\") # stien til datafilen når det er i data.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d34352",
   "metadata": {},
   "source": [
    "## Part 2: Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9e81be",
   "metadata": {},
   "source": [
    "### 2.1. Data Description and Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7749fc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddc07f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first few rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b990414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the data types of each column\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95f11e3",
   "metadata": {},
   "source": [
    "### 2.2. Data Preprocessing and Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e78491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values\n",
    "df = df.dropna(subset=[\"is_match\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f651cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the column names to don't use underscores and to use upper first letters\n",
    "df.columns = [col.replace('_', ' ').title() for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5540537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the column names\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bbdbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all column names before making changes\n",
    "cols_before = set(df.columns)\n",
    "\n",
    "# Drop unwanted columns (gender, religion, etc.)\n",
    "df = df.drop(\n",
    "    columns=[\n",
    "        \"Dated Wants To Date\",\n",
    "        \"Dater Wants To Date\",\n",
    "        \"Same Race Importance For Dater\",\n",
    "        \"Same Religion Importance For Dater\"\n",
    "    ],\n",
    "    errors=\"ignore\"  # ignore errors if any columns are missing\n",
    ")\n",
    "\n",
    "# Drop all columns containing the word 'Race'\n",
    "race_cols = [col for col in df.columns if \"Race\" in col]\n",
    "df = df.drop(columns=race_cols, errors=\"ignore\")\n",
    "\n",
    "# Compare column sets before and after to see which columns were removed for verification\n",
    "cols_after = set(df.columns)\n",
    "removed_cols = cols_before - cols_after\n",
    "\n",
    "# Print removed columns\n",
    "print(\"Removed columns:\", removed_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695dc63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables to numerical dummy variables using one-hot encoding\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1611c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe after cleaning\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f9fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics of the dataframe\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d07247c",
   "metadata": {},
   "source": [
    "### 2.3. Split Features and Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdee81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target variable\n",
    "# \"Is Match\" is the target variable and is binary (0 or 1) indicating if there was a match or not\n",
    "X = df.drop(\"Is Match\", axis=1)\n",
    "y = df[\"Is Match\"]\n",
    "\n",
    "# 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.20, # the dataset is small, so use 20% for testing\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "\n",
    "# Define K-fold cross-validation on the training data\n",
    "# This 'cv' object will be used later when training/evaluating models\n",
    "# CV means cross-validation\n",
    "cv = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931358eb",
   "metadata": {},
   "source": [
    "## Part 3: Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2b5844",
   "metadata": {},
   "source": [
    "### 3.1. Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05cb96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131fc0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model: always predicts the most frequent class in y_train\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "# Train on the *original* training data\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_dummy = dummy_clf.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "accuracy_dummy = accuracy_score(y_test, y_pred_dummy)\n",
    "precision_dummy = precision_score(y_test, y_pred_dummy, zero_division=0)\n",
    "recall_dummy = recall_score(y_test, y_pred_dummy, zero_division=0)\n",
    "f1_dummy = f1_score(y_test, y_pred_dummy, zero_division=0)\n",
    "\n",
    "print(\"=== DummyClassifier (Most Frequent) ===\")\n",
    "print(f\"Accuracy:  {accuracy_dummy:.3f}\")\n",
    "print(f\"Precision: {precision_dummy:.3f}\")\n",
    "print(f\"Recall:    {recall_dummy:.3f}\")\n",
    "print(f\"F1-score:  {f1_dummy:.3f}\\n\")\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_dummy, zero_division=0))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_dummy = confusion_matrix(y_test, y_pred_dummy)\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm_dummy)\n",
    "\n",
    "sns.heatmap(cm_dummy, annot=True, fmt=\"d\")\n",
    "plt.title(\"Dummy Classifier – Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19b0ce0",
   "metadata": {},
   "source": [
    "### 3.2. Logistic Regression\n",
    "#### 3.2.1. Logistic Regression with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2e12ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline: scaling + model\n",
    "log_reg_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"log_reg\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Run cross-validation on the training data\n",
    "lt_cv_scores = cross_val_score(\n",
    "    log_reg_pipeline,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=cv,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Logisitic Regression CV Scores:\", lt_cv_scores)\n",
    "print(\"Logisitic Regression mean CV Score:\", lt_cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e45d18",
   "metadata": {},
   "source": [
    "#### 3.2.2. Fine-Tune Logistic Regression with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f851372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    \"log_reg__C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    \"log_reg__penalty\": [\"l1\", \"l2\"],\n",
    "    \"log_reg__solver\": [\"liblinear\", \"saga\"],\n",
    "    \"log_reg__class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid = GridSearchCV(\n",
    "    estimator=log_reg_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the grid search on the training data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and best CV score\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4752b0d",
   "metadata": {},
   "source": [
    "#### 3.3. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9402ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree without scaling (tree models are scale-invariant)\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Run cross-validation on the training data for performance evaluation\n",
    "dt_cv_scores = cross_val_score(\n",
    "    dt_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=cv,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "# Print Decision Tree CV scores\n",
    "print(\"Decision Tree CV scores:\", dt_cv_scores)\n",
    "print(\"Decision Tree mean CV score:\", dt_cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d83eb3",
   "metadata": {},
   "source": [
    "##### 3.3.1. Reduced Decision Tree for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee94b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a reduced Decision Tree for visualization with max depth of 3\n",
    "dtree_small = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=3\n",
    ")\n",
    "\n",
    "# Fit the reduced Decision Tree model on the training data\n",
    "dtree_small.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4aacf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Decision Tree\n",
    "# Create a figure with specified size\n",
    "plt.figure(figsize=(13, 8))\n",
    "\n",
    "# Plot the tree\n",
    "tree.plot_tree(\n",
    "    dtree_small,\n",
    "class_names=[\"Unsuccessful Match\", \"Successful Match\"],\n",
    "    feature_names=list(X_train.columns),\n",
    "    filled=True,\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"reduced_tree.png\", bbox_inches=\"tight\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f0770a",
   "metadata": {},
   "source": [
    "#### 3.4. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90367ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest without scaling\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Run cross-validation on the training data\n",
    "rf_cv_scores = cross_val_score(\n",
    "    rf_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=cv,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "# Print Random Forest CV scores\n",
    "print(\"Random Forest CV scores:\", rf_cv_scores)\n",
    "print(\"Random Forest mean CV score:\", rf_cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02c0ac4",
   "metadata": {},
   "source": [
    "#### 3.4.1 Random Forest tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8335cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameter grid \n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [200, 500],                 \n",
    "    \"max_depth\": [None, 5, 10, 20],             \n",
    "    \"min_samples_split\": [2, 5, 10],            \n",
    "    \"min_samples_leaf\": [1, 2, 4],              \n",
    "    \"max_features\": [\"sqrt\", \"log2\"],            \n",
    "    \"bootstrap\": [True]                         \n",
    "}\n",
    "\n",
    "# Grid search\n",
    "rf_grid = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=rf_param_grid,\n",
    "    cv=cv,                                      \n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"RF best params:\", rf_grid.best_params_)\n",
    "print(\"RF best CV accuracy:\", rf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11015094",
   "metadata": {},
   "source": [
    "#### 3.5. K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fc1985",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"knn\", KNeighborsClassifier(\n",
    "        n_neighbors=15,\n",
    "        weights=\"distance\",\n",
    "        p=2\n",
    "    ))\n",
    "])\n",
    "\n",
    "knn_cv_scores = cross_val_score(\n",
    "    knn_pipeline,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=cv,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"KNN CV scores (scaled):\", knn_cv_scores)\n",
    "print(\"KNN mean CV score (scaled):\", knn_cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1025c6",
   "metadata": {},
   "source": [
    "### 3.5.1 KNN tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cefeaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"scaler\": [StandardScaler(), RobustScaler(), \"passthrough\"],\n",
    "    \"knn__n_neighbors\": [3, 6, 9,12,15,19, 24, 48, 96],\n",
    "    \"knn__weights\": [\"uniform\", \"distance\"],\n",
    "    \"knn__p\": [1, 2],                      # 1=Manhattan, 2=Euclidean\n",
    "}\n",
    "\n",
    "KNN_grid = GridSearchCV(\n",
    "    estimator=knn_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,                                 \n",
    "    scoring=\"accuracy\",                    \n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    "    verbose=3\n",
    ")\n",
    "\n",
    "KNN_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\", KNN_grid.best_params_)\n",
    "print(\"Best CV score:\", KNN_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7d50bf",
   "metadata": {},
   "source": [
    "### 4. Results and Evaluation\n",
    "#### 4.1. Results From the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42df1264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect CV results from the three models\n",
    "results = {\n",
    "    \"Logistic Regression\": lt_cv_scores.mean(),\n",
    "    \"Decision Tree\": dt_cv_scores.mean(),\n",
    "    \"Random Forest\": rf_cv_scores.mean(),\n",
    "    \"KNN\": CV_grid_search.best_score_\n",
    "}\n",
    "\n",
    "# Convert to a clean table\n",
    "results_table = pd.DataFrame({\n",
    "    \"Model\": list(results.keys()),\n",
    "    \"CV Accuracy\": [round(v, 4) for v in results.values()]\n",
    "})\n",
    "\n",
    "# Display results sorted by accuracy\n",
    "results_table.sort_values(\"CV Accuracy\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2fd01b",
   "metadata": {},
   "source": [
    "### ?. Test Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aea2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
